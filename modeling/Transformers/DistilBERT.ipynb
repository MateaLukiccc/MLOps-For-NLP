{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import *\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import mlflow\n",
    "from mlflow import log_metric, log_param\n",
    "import dagshub\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dagshub.init(repo_owner='matealukiccc', repo_name='MLOps-For-NLP', mlflow=True)\n",
    "mlflow.set_tracking_uri(uri=\"https://dagshub.com/MateaLukiccc/MLOps-For-NLP.mlflow\")\n",
    "mlflow.set_experiment(\"ELECTRA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"text\"], padding=True, truncation=True, max_length=512)\n",
    "    tokenized_inputs[\"labels\"] = examples[\"label\"]\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "ds = load_dataset(\"csv\", data_files=\"data/preprocessed_train.csv\")\n",
    "ds2 = load_dataset(\"csv\", data_files=\"data/preprocessed_test.csv\")\n",
    "\n",
    "train_testvalid = ds['train'].train_test_split(test_size=0.2)\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5)\n",
    "\n",
    "train_test_valid_dataset = DatasetDict({\n",
    "    'train': train_testvalid['train'],\n",
    "    'test': train_testvalid['test'],\n",
    "    'valid': ds2['train']})\n",
    "\n",
    "tokenized_ds = train_test_valid_dataset.map(preprocess_function, batched=True)\n",
    "print(tokenized_ds[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    print(f\"Predictions shape: {predictions.shape}, Labels shape: {labels.shape}\")\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    accuracy_result = accuracy.compute(predictions=predictions, references=labels)\n",
    "    precision_result = precision.compute(predictions=predictions, references=labels, average='macro') \n",
    "    recall_result = recall.compute(predictions=predictions, references=labels, average='macro') \n",
    "    f1_result = f1.compute(predictions=predictions, references=labels, average='macro')  \n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_result[\"accuracy\"],\n",
    "        \"precision\": precision_result[\"precision\"],\n",
    "        \"recall\": recall_result[\"recall\"],\n",
    "        \"f1\": f1_result[\"f1\"],\n",
    "    }\n",
    "\n",
    "def compute_confusion_matrix(trainer, eval_dataset):\n",
    "    # Predikcija na eval_dataset\n",
    "    predictions = trainer.predict(eval_dataset)\n",
    "    pred_labels = np.argmax(predictions.predictions, axis=1)\n",
    "    true_labels = np.array(eval_dataset['label'])\n",
    "    \n",
    "    # Izraƒçunavanje konfuzione matrice\n",
    "    cm = confusion_matrix(true_labels, pred_labels)\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def make_model_contiguous(model):\n",
    "    for param in model.parameters():\n",
    "        if not param.is_contiguous():\n",
    "            param.data = param.data.contiguous()\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def on_epoch_end(self, args, state, control):\n",
    "        super().on_epoch_end(args, state, control)\n",
    "        make_model_contiguous(self.model)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    load_best_model_at_end=False\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    mlflow.log_param(\"embedding_dim\", None)\n",
    "    mlflow.log_param(\"hidden_size\", None)\n",
    "    mlflow.log_param(\"optimizer\", \"AdamW\")\n",
    "    mlflow.log_param(\"learning_rate\", 2e-5)\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for param in trainer.model.parameters():\n",
    "    if not param.is_contiguous():\n",
    "        param.data = param.data.contiguous()\n",
    "\n",
    "trainer.save_model(\"trained_model\")\n",
    "\n",
    "# alternative\n",
    "# mlflow.transformers.save_model(\n",
    "#         transformers_model={\"model\": trainer.model, \"tokenizer\": trainer.tokenizer},\n",
    "#         path=\"trained_model_2\",\n",
    "#         task=\"text-classification\"\n",
    "#     )\n",
    "mlflow.log_artifacts(\"trained_model\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "test_metrics = trainer.evaluate(eval_dataset=tokenized_ds[\"test\"])\n",
    "mlflow.log_metric(\"accuracy\", test_metrics['eval_accuracy'])\n",
    "mlflow.log_metric(\"f1_score\", test_metrics['eval_f1'])\n",
    "mlflow.log_metric(\"recall\", test_metrics['eval_recall'])\n",
    "\n",
    "mlflow.log_param(\"embedding_dim\", None)\n",
    "mlflow.log_param(\"hidden_size\", None)\n",
    "mlflow.log_param(\"optimizer\", \"AdamW\")\n",
    "mlflow.log_param(\"learning_rate\", 2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=compute_confusion_matrix(trainer, tokenized_arxiv[\"test\"]))\n",
    "disp.plot(cmap='viridis')\n",
    "plt.savefig(\"confusion_matrix.png\")\n",
    "mlflow.log_artifact(\"confusion_matrix.png\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
